#!/usr/bin/env python3
"""
Test script to validate information-theoretic estimators on synthetic data.

This script generates synthetic data with known information-theoretic properties
and verifies that the estimators produce reasonable results.
"""

import numpy as np
import sys
import os

# Add parent directory to path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from core.information_theoretic_evaluation import MinimalInformationPartitionEvaluator


def test_independent_variables():
    """
    Test MI between independent variables (should be ~0).
    """
    print("\n" + "="*80)
    print("TEST 1: Independent Variables")
    print("="*80)
    print("Generating independent Z and Y...")
    print("Expected: I(Z;Y) ‚âà 0")

    np.random.seed(42)
    n_samples = 5000

    # Independent continuous and discrete variables
    Z = np.random.randn(n_samples, 5)
    Y = np.random.randint(0, 10, size=n_samples)

    evaluator = MinimalInformationPartitionEvaluator(n_neighbors=5, n_bootstrap=0)
    mi = evaluator.mutual_information(Z, Y, apply_pca=False)

    print(f"Result: I(Z;Y) = {mi:.6f}")
    print(f"Status: {'‚úÖ PASS' if mi < 0.1 else '‚ùå FAIL'} (threshold: < 0.1)")

    return mi < 0.1


def test_deterministic_relationship():
    """
    Test MI between deterministically related variables (should be high).
    """
    print("\n" + "="*80)
    print("TEST 2: Deterministic Relationship")
    print("="*80)
    print("Generating Z such that Y is deterministically determined by Z...")
    print("Expected: I(Z;Y) ‚âà H(Y) ‚âà log(10) ‚âà 2.3 nats")

    np.random.seed(42)
    n_samples = 5000

    # Z determines Y perfectly
    Z = np.random.randn(n_samples, 5)
    # Y is determined by first dimension of Z
    Y = (Z[:, 0] > 0).astype(int)  # Binary: 0 or 1

    evaluator = MinimalInformationPartitionEvaluator(n_neighbors=5, n_bootstrap=0)
    mi = evaluator.mutual_information(Z, Y, apply_pca=False)

    # For binary Y, H(Y) ‚âà 0.69 nats (log(2))
    expected_mi = 0.69
    print(f"Result: I(Z;Y) = {mi:.6f}")
    print(f"Expected: ‚âà {expected_mi:.2f} nats (H(binary variable))")
    print(f"Status: {'‚úÖ PASS' if 0.3 < mi < 1.5 else '‚ùå FAIL'} (threshold: 0.3 < MI < 1.5)")

    return 0.3 < mi < 1.5


def test_conditional_independence():
    """
    Test conditional MI: I(Z;Y|D) when Z and Y are independent given D.
    """
    print("\n" + "="*80)
    print("TEST 3: Conditional Independence")
    print("="*80)
    print("Generating Z, Y, D such that Z ‚ä• Y | D...")
    print("Expected: I(Z;Y|D) ‚âà 0")

    np.random.seed(42)
    n_samples = 5000

    # D is the conditioning variable
    D = np.random.randint(0, 3, size=n_samples)

    # Z and Y are both determined by D, but independent given D
    Z = np.zeros((n_samples, 3))
    Y = np.zeros(n_samples, dtype=int)

    for d in range(3):
        mask = (D == d)
        # For each value of D, Z is random and Y is also random (but different distribution)
        Z[mask] = np.random.randn(np.sum(mask), 3) + d  # Mean depends on D
        Y[mask] = np.random.randint(0, 2, size=np.sum(mask))  # Independent of Z given D

    evaluator = MinimalInformationPartitionEvaluator(n_neighbors=5, n_bootstrap=0)
    cmi = evaluator.conditional_mi(Z, Y, D, apply_pca=False)

    print(f"Result: I(Z;Y|D) = {cmi:.6f}")
    print(f"Status: {'‚úÖ PASS' if cmi < 0.3 else '‚ùå FAIL'} (threshold: < 0.3)")

    return cmi < 0.3


def test_interaction_information():
    """
    Test interaction information I(Z;Y;D) with synergistic relationship.
    """
    print("\n" + "="*80)
    print("TEST 4: Interaction Information")
    print("="*80)
    print("Generating Z, Y, D with synergistic interaction (XOR-like)...")
    print("Expected: I(Z;Y;D) > 0 (positive interaction)")

    np.random.seed(42)
    n_samples = 5000

    # Create XOR-like relationship: Y = XOR(D, Z_discrete)
    D = np.random.randint(0, 2, size=n_samples)
    Z_base = np.random.randn(n_samples)
    Z_discrete = (Z_base > 0).astype(int)
    Y = np.logical_xor(D, Z_discrete).astype(int)

    # Add noise dimensions to Z
    Z = np.column_stack([Z_base, np.random.randn(n_samples, 4)])

    evaluator = MinimalInformationPartitionEvaluator(n_neighbors=5, n_bootstrap=0)
    interaction = evaluator.interaction_information(Z, Y, D, apply_pca=False)

    print(f"Result: I(Z;Y;D) = {interaction:.6f}")
    print(f"Note: Can be positive (synergy) or negative (redundancy)")
    print(f"Status: ‚úÖ PASS (computed successfully)")

    # For XOR, we expect positive interaction (synergy)
    return True  # Just check it runs without errors


def test_joint_mi():
    """
    Test joint MI: I(Z;Y,D) = I(Z;Y) + I(Z;D|Y).
    """
    print("\n" + "="*80)
    print("TEST 5: Joint Mutual Information")
    print("="*80)
    print("Testing decomposition: I(Z;Y,D) = I(Z;Y) + I(Z;D|Y)...")

    np.random.seed(42)
    n_samples = 5000

    # Create correlated variables
    Y = np.random.randint(0, 5, size=n_samples)
    D = np.random.randint(0, 3, size=n_samples)
    Z = np.column_stack([
        Y + np.random.randn(n_samples) * 0.5,  # Z correlated with Y
        D + np.random.randn(n_samples) * 0.5,  # Z correlated with D
        np.random.randn(n_samples, 3)          # Random dimensions
    ])

    evaluator = MinimalInformationPartitionEvaluator(n_neighbors=5, n_bootstrap=0)

    # Method 1: Direct computation
    i_z_yd = evaluator.joint_mutual_information(Z, Y, D, apply_pca=False)

    # Method 2: Decomposition
    i_zy = evaluator.mutual_information(Z, Y, apply_pca=False)
    i_zd_given_y = evaluator.conditional_mi(Z, D, Y, apply_pca=False)
    i_z_yd_decomposed = i_zy + i_zd_given_y

    print(f"Direct computation:      I(Z;Y,D) = {i_z_yd:.6f}")
    print(f"Decomposition:           I(Z;Y) + I(Z;D|Y) = {i_z_yd_decomposed:.6f}")
    print(f"Difference: {abs(i_z_yd - i_z_yd_decomposed):.6f}")
    print(f"Status: {'‚úÖ PASS' if abs(i_z_yd - i_z_yd_decomposed) < 0.5 else '‚ùå FAIL'} (threshold: < 0.5)")

    return abs(i_z_yd - i_z_yd_decomposed) < 0.5


def test_dimensionality_reduction():
    """
    Test PCA dimensionality reduction for high-dimensional Z.
    """
    print("\n" + "="*80)
    print("TEST 6: Dimensionality Reduction (PCA)")
    print("="*80)
    print("Generating high-dimensional Z (50 dims)...")
    print("Expected: PCA reduces to < 30 dims automatically")

    np.random.seed(42)
    n_samples = 2000

    # High-dimensional Z with structure
    Z_lowdim = np.random.randn(n_samples, 5)
    # Expand to 50 dims with linear combinations
    random_matrix = np.random.randn(5, 50)
    Z = Z_lowdim @ random_matrix + np.random.randn(n_samples, 50) * 0.1

    Y = np.random.randint(0, 10, size=n_samples)

    evaluator = MinimalInformationPartitionEvaluator(
        n_neighbors=5,
        n_bootstrap=0,
        max_dims=30,
        pca_variance=0.95
    )

    print(f"Original Z shape: {Z.shape}")
    mi = evaluator.mutual_information(Z, Y, apply_pca=True)
    print(f"I(Z;Y) = {mi:.6f} (computed with PCA)")
    print(f"Status: ‚úÖ PASS (PCA applied automatically for dims > 30)")

    return True


def test_minimal_partition_evaluation():
    """
    Test full partition evaluation on synthetic minimally partitioned representation.
    """
    print("\n" + "="*80)
    print("TEST 7: Minimal Partition Evaluation")
    print("="*80)
    print("Creating synthetic minimally partitioned representation...")

    np.random.seed(42)
    n_samples = 3000

    # Create labels
    Y = np.random.randint(0, 5, size=n_samples)
    D = np.random.randint(0, 3, size=n_samples)

    # Create minimally partitioned latents
    # z_y: purely class-specific
    z_y = np.column_stack([
        Y + np.random.randn(n_samples) * 0.3,
        np.random.randn(n_samples, 4)
    ])

    # z_d: purely domain-specific
    z_d = np.column_stack([
        D + np.random.randn(n_samples) * 0.3,
        np.random.randn(n_samples, 4)
    ])

    # z_dy: interaction (depends on both Y and D)
    z_dy = np.column_stack([
        Y * D + np.random.randn(n_samples) * 0.5,
        np.random.randn(n_samples, 4)
    ])

    # z_x: residual (independent of Y and D)
    z_x = np.random.randn(n_samples, 5)

    print("Expected properties:")
    print("  - I(z_y;Y|D) should be HIGH")
    print("  - I(z_y;D|Y) should be LOW")
    print("  - I(z_d;D|Y) should be HIGH")
    print("  - I(z_d;Y|D) should be LOW")
    print("  - I(z_x;Y,D) should be LOW")

    evaluator = MinimalInformationPartitionEvaluator(
        n_neighbors=5,
        n_bootstrap=0  # Disable bootstrap for speed
    )

    results = evaluator.evaluate_latent_partition(
        z_y, z_d, z_dy, z_x,
        Y, D,
        compute_bootstrap=False
    )

    # Check key properties
    checks = [
        ("I(z_y;Y|D) > 0.5", results['metrics']['I(z_y;Y|D)'] > 0.5),
        ("I(z_y;D|Y) < 0.5", results['metrics']['I(z_y;D|Y)'] < 0.5),
        ("I(z_d;D|Y) > 0.5", results['metrics']['I(z_d;D|Y)'] > 0.5),
        ("I(z_d;Y|D) < 0.5", results['metrics']['I(z_d;Y|D)'] < 0.5),
        ("I(z_x;Y,D) < 0.5", results['metrics']['I(z_x;Y,D)'] < 0.5),
        ("Partition quality > 0.3", results['metrics']['partition_quality'] > 0.3),
    ]

    print("\nValidation checks:")
    all_passed = True
    for desc, passed in checks:
        print(f"  {desc}: {'‚úÖ PASS' if passed else '‚ùå FAIL'}")
        all_passed = all_passed and passed

    return all_passed


def main():
    """Run all validation tests"""
    print("="*80)
    print("INFORMATION-THEORETIC ESTIMATOR VALIDATION")
    print("Testing on Synthetic Data with Known Properties")
    print("="*80)

    tests = [
        ("Independent Variables", test_independent_variables),
        ("Deterministic Relationship", test_deterministic_relationship),
        ("Conditional Independence", test_conditional_independence),
        ("Interaction Information", test_interaction_information),
        ("Joint MI Decomposition", test_joint_mi),
        ("Dimensionality Reduction", test_dimensionality_reduction),
        ("Full Partition Evaluation", test_minimal_partition_evaluation),
    ]

    results = []
    for name, test_func in tests:
        try:
            passed = test_func()
            results.append((name, passed))
        except Exception as e:
            print(f"\n‚ùå ERROR in {name}: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))

    # Summary
    print("\n" + "="*80)
    print("TEST SUMMARY")
    print("="*80)

    passed_count = sum(1 for _, passed in results if passed)
    total_count = len(results)

    for name, passed in results:
        status = "‚úÖ PASS" if passed else "‚ùå FAIL"
        print(f"{status}: {name}")

    print("\n" + "="*80)
    print(f"OVERALL: {passed_count}/{total_count} tests passed")
    if passed_count == total_count:
        print("üéâ All tests passed! IT estimators are working correctly.")
    else:
        print("‚ö†Ô∏è  Some tests failed. Please review the output above.")
    print("="*80)

    return 0 if passed_count == total_count else 1


if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
